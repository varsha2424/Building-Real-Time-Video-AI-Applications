{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00923ef",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3eba9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Real-Time Video AI Applications #\n",
    "In the modern world, cameras are everywhere, capturing an abundance of data that can be used to generate business insights, unlock process efficiencies, and improve revenue streams. Transforming video inputs into usable insights is a computationally intensive task. This type of processing can be done at the edge near the sensors themselves, on-premise, or in the cloud. Once the AI-based insights have been generated, we can pass them downstream for further processing such as create alerts based on defined criteria, perform further analytics, or make visualizations to monitor trends and patterns. Building video AI applications can be complex, requiring developers to design efficient systems with multiple functional parts, train high-performing neural network models, and understand the implications of their choices. Fortunately, there are some powerful tools we can use to simplify the process. \n",
    "<p><img src='images/iva.png' width='720px'></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b16072",
   "metadata": {},
   "source": [
    "## Learning Objectives ##\n",
    "In this notebook, you will learn important concepts about Real-Time Video AI Applications, including: \n",
    "* Use Cases and Different Approaches for Drawing Insights Using Video AI\n",
    "* Challenges with Building Video AI Applications\n",
    "* Components of a Video AI Application\n",
    "* How to Achieve Near Real-Time Analytics by Streaming\n",
    "\n",
    "**Table of Contents**\n",
    "<br>\n",
    "This notebook covers the below sections: \n",
    "1. [Video AI Use Cases](#s1)\n",
    "    * [Video AI Tasks](#s1.1)\n",
    "2. [Video AI Application Framework](#s2)\n",
    "2. [Real-Time Streaming Analytics Done on the Edge](#s3)\n",
    "3. [Video AI Application Challenges](#s4)\n",
    "4. [DeepStream SDK, TAO Toolkit, and TensorRT for Video AI Applications](#s5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccecd80a",
   "metadata": {},
   "source": [
    "<a name='s1'></a>\n",
    "## Video AI Use Cases: ##\n",
    "Intelligent video analytics is increasingly impacting our daily lives. The opportunities for applications using video AI is limitless. Here are some examples: \n",
    "<p><img src='images/use_cases.png' width='720px' /></p>\n",
    "\n",
    "* **Access control** at airports or other checkpoints\n",
    "* **Managing operations** for logistic and manufacturing such as warehouse balancing at product distribution centers\n",
    "* **Traffic flow and parking management** for _smart cities_\n",
    "* **Retail analytics** to improve customer experience\n",
    "* **Optical inspection** at factory assembly line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d9462",
   "metadata": {},
   "source": [
    "<a name='s1.1'></a>\n",
    "### Video AI Tasks ###\n",
    "At the heart of these video AI applications is one or more machine learning models to generate insights from the video inputs. These are generally deep learning neural network models that have been trained for a specific task. There are numerous approaches for drawing insight from videos using *machine learning* such as: \n",
    "* **Classification** is used for identifying the object contained in an image. It is the task of labeling the given frame with one of the classes that the model has been trained with\n",
    "* **Localization** uses regression to return the coordinates of the potential object within the frame\n",
    "* **Object detection**, which includes _image localization_, can specify the location of multiple objects in a frame\n",
    "* **Segmentation** provides pixel level accuracy by creating a fine-grained segmentation mask around the detected object. Applications for segmentation include: an AI powered green screen to blur or change the background of the frame, autonomous driving where you want to segment the road and background, or for manufacturing to identify microscopic level defects\n",
    "\n",
    "<p><img src='images/image_processing_problems.png' width='720px'></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4251adf4",
   "metadata": {},
   "source": [
    "<a name='s2'></a>\n",
    "## Video AI Application Framework ##\n",
    "Nearly every video AI application uses a similar framework. Generally, a video AI application takes one or more input video streams, performs decoding and muxing (or aggregating), preprocesses the batch, and puts the data through AI inference. Afterwards, the AI-based insight, combined with the original video, can be 1) encoded for storage, 2) used to create a composite for display, or 3) passed downstream for further analytics.\n",
    "<p><img src='images/iva_framework.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f273d",
   "metadata": {},
   "source": [
    "<a name='s3'></a>\n",
    "## Real-Time Streaming Analytics Done on the Edge ##\n",
    "<p><img src='images/iva_stream_edge_inference.png' width='720px' /></p>\n",
    "\n",
    "Analyzing large amounts of data based on complex machine learning algorithms requires significant computational capabilities, therefore this has traditionally taken place in an on-premise data center or cloud-based infrastructure with the most powerful hardware. They provide massive processing, storage, and memory resources. However, a major drawback of this deployment strategy is **latency**, which occurs when data are collected from sensors and transmitted to the cloud or data center. This delay becomes more obvious as the amount of video data created and consumed grow, causing bandwidth to be jammed. With the arrival of powerful, low-energy-consumption IoT devices, computations can now be executed on edge devices. We want to use [stream processing](https://en.wikipedia.org/wiki/Streaming_media) on the edge to provide analytics in or near real-time. Inference at the edge can potentially reduce the time for a result from a few seconds to a fraction of a second. When inference is performed on the edge near the sensors, we can also choose if and how much of the raw video is transmitted and stored. Inference on the edge can provide some benefits: \n",
    "* **Faster response time** as a result of the low time-to-insight, which is particularly meaningful when data-drive decision-making have to be performed immediately\n",
    "* **Lower bandwidth cost** when the amount of raw video to transmit can be managed\n",
    "* **Mitigate network related problems** that occur when sensors are used in remote locations with no or low network connectivity\n",
    "* **Improve data privacy and security** since edge devices can be programmed to discard sensitive data after they have been processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137514c",
   "metadata": {},
   "source": [
    "<a name='s4'></a>\n",
    "## Video AI Application Challenges ##\n",
    "While deep learning and computer vision models have advanced to the point where they outperform humans in many tasks, building video AI applications to utilize these technologies has been a challenge. For one, building and productionizing video AI applications take extensive effort and optimizing these systems can be a tedious task. Some of the other challenges include: \n",
    "* Requirement for expertise in *deep learning*, which could mean proficiency in one or more of the popular frameworks like TensorFlow, PyTorch, Caffe, etc., as well as knowledge of neural network architectures in general\n",
    "* Need for efficient hardware and reliable software for development\n",
    "* Barriers of real-time data processing\n",
    "* Applications need the flexibility of being able to run on a wide variety of configurations that range from small edge devices to public clouds. Developers want a platform that allows them to develop once and deploy in many configurations without having to maintain different software stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b9b1f",
   "metadata": {},
   "source": [
    "<a name='s5'></a>\n",
    "## DeepStream SDK, TAO Toolkit, and TensorRT for Video AI Applications ##\n",
    "[DeepStream](https://developer.nvidia.com/deepstream-sdk), [TAO Toolkit](https://developer.nvidia.com/tao), and [TensorRT](https://developer.nvidia.com/tensorrt) tackle these challenges to enable the creation of AI-based hardware-accelerated intelligent video analytics applications. Together they simplify the process of developing end-to-end services and solutions for transforming pixels and sensor data to actionable insights. \n",
    "<p><img src='images/tao_toolkit_deepstream.png' width='720px'></p>\n",
    "\n",
    "**DeepStream SDK**\n",
    "<br>\n",
    "With the DeepStream SDK, you can build video stream processing pipelines for video decode/encode, image scaling and conversion, and AI-inference using an intuitive framework. DeepStream applications use hardware-accelerated plugins for complete end-to-end performance optimization, thus enabling near real-time analytics. \n",
    "<br>\n",
    "\n",
    "**TAO Toolkit**\n",
    "<br>\n",
    "The TAO Toolkit can be used to create models for vision AI tasks such as object detection, classification, and segmentation. It's a simple, easy-to-use training toolkit that enables users transfer learning from pre-trained models to your customized needs. In addition, the TAO Toolkit also enables model optimization such as model pruning to reduce the overall size of the model and quantization. \n",
    "<br>\n",
    "\n",
    "**TensorRT**\n",
    "<br>\n",
    "TensorRT is an SDK for high-performance deep learning inference. It includes a deep learning inference optimizer and runtime to deliver low latency and high throughput.\n",
    "<br>\n",
    "\n",
    "Together, the DeepStream SDK, TAO Toolkit, and TensorRT enable developers to focus their efforts on: \n",
    "* Deciding the approach to extract information from video data\n",
    "* Training and optimizing models for doing so\n",
    "* Drawing meaningful insights from model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606d32c",
   "metadata": {},
   "source": [
    "**Well Done!** When you're ready, let's move to the [next notebook](./02_introduction_to_the_DeepStream_SDK.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a38f45",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
